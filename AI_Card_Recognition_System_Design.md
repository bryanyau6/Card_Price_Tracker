# AI å¡ç‰‡è­˜åˆ¥ç³»çµ±è¨­è¨ˆæ–¹æ¡ˆ

**ç‰ˆæœ¬:** 1.0  
**æ—¥æœŸ:** 2025-12-01  
**ä½œè€…:** TCGE æŠ€è¡“åœ˜éšŠ

---

## ğŸ“Œ å•é¡Œåˆ†æ

ä½ ç›®å‰çš„çŸ¥è­˜åº«ç³»çµ±ä½¿ç”¨çš„æ˜¯ï¼š
- **OCR + è‰²å½©åˆ†æ + è¦å‰‡åŒ¹é…** çš„å‚³çµ±æ–¹å¼
- æº–ç¢ºåº¦å—é™æ–¼ï¼šOCR è­˜åˆ¥ç‡ã€è‰²å½©è®Šç•°ã€ç‰¹å¾µæå–ç²¾åº¦

**eBay ç­‰å¤§å¹³å°ä½¿ç”¨çš„æŠ€è¡“ï¼š**
- **æ·±åº¦å­¸ç¿’åœ–åƒåµŒå…¥ (Image Embeddings)**
- **å‘é‡ç›¸ä¼¼åº¦æœå°‹ (Vector Similarity Search)**
- **CLIP å¤šæ¨¡æ…‹æ¨¡å‹**

---

## ğŸš€ æ¨è–¦æ–¹æ¡ˆï¼šä¸‰å±¤æ¶æ§‹

### æ–¹æ¡ˆå°æ¯”

| æ–¹æ¡ˆ | æº–ç¢ºåº¦ | æˆæœ¬ | é–‹ç™¼æ™‚é–“ | é©ç”¨å ´æ™¯ |
|:---|:---:|:---:|:---:|:---|
| **æ–¹æ¡ˆ A: CLIP + å‘é‡è³‡æ–™åº«** | â­â­â­â­â­ | ä½ | 1-2 é€± | âœ… **æ¨è–¦** |
| **æ–¹æ¡ˆ B: è‡ªè¨“ç·´ CNN æ¨¡å‹** | â­â­â­â­ | é«˜ | 4-8 é€± | éœ€è¦æ¥µé«˜æº–ç¢ºåº¦ |
| **æ–¹æ¡ˆ C: å•†æ¥­ API (Google Vision)** | â­â­â­â­ | ä¸­ | 1 é€± | å¿«é€Ÿä¸Šç·š |

---

## ğŸ“¦ æ–¹æ¡ˆ Aï¼šCLIP + Milvus å‘é‡è³‡æ–™åº« (å¼·çƒˆæ¨è–¦)

é€™æ˜¯ **eBay ä½¿ç”¨çš„æ ¸å¿ƒæŠ€è¡“**ï¼Œé©åˆä½ çš„å ´æ™¯ï¼š

### å·¥ä½œåŸç†
```
æ‹ç…§/ä¸Šå‚³åœ–ç‰‡ â†’ CLIP æ¨¡å‹æå–åœ–åƒç‰¹å¾µå‘é‡ (512ç¶­)
                            â†“
                    å‘é‡è³‡æ–™åº« (Milvus/Pinecone)
                            â†“
                    æ‰¾å‡ºæœ€ç›¸ä¼¼çš„å¡ç‰‡ (Top-5)
                            â†“
                    è¿”å›å¡è™Ÿã€åƒ¹æ ¼ç­‰è³‡è¨Š
```

### æ¶æ§‹åœ–
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ç”¨æˆ¶ç•Œé¢                                  â”‚
â”‚   ğŸ“· æ‹ç…§ä¸Šå‚³ â†’ é è¦½è£åˆ‡ â†’ è­˜åˆ¥çµæœ â†’ ç¢ºèªå¡ç‰‡ â†’ åŠ å…¥è²·å–å–®      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      FastAPI å¾Œç«¯                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ åœ–åƒé è™•ç†    â”‚â†’ â”‚ CLIP æ¨¡å‹     â”‚â†’ â”‚ å‘é‡ç›¸ä¼¼åº¦æœå°‹    â”‚   â”‚
â”‚  â”‚ (è£åˆ‡/ç¸®æ”¾)   â”‚  â”‚ (ç‰¹å¾µæå–)    â”‚  â”‚ (Milvus/Pinecone) â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        è³‡æ–™å±¤                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚  â”‚ PostgreSQL      â”‚  â”‚ Milvus          â”‚                       â”‚
â”‚  â”‚ (å¡ç‰‡è³‡æ–™/åƒ¹æ ¼) â”‚  â”‚ (åœ–åƒå‘é‡ç´¢å¼•)  â”‚                       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ ¸å¿ƒå„ªå‹¢

1. **é›¶æ¨£æœ¬å­¸ç¿’ (Zero-Shot)**
   - æ–°å¡ç‰‡ä¸Šæ¶æ™‚ï¼Œåªéœ€å°‡åœ–ç‰‡è½‰æˆå‘é‡å­˜å…¥è³‡æ–™åº«
   - ç„¡éœ€é‡æ–°è¨“ç·´æ¨¡å‹

2. **é«˜æº–ç¢ºåº¦**
   - CLIP åœ¨ ImageNet é”åˆ° 76.2% æº–ç¢ºåº¦
   - å°æ–¼ç‰¹å®šé ˜åŸŸï¼ˆå¡ç‰Œï¼‰ï¼Œæº–ç¢ºåº¦æ›´é«˜

3. **å¿«é€Ÿæœå°‹**
   - Milvus å¯åœ¨æ¯«ç§’å…§æœå°‹æ•¸ç™¾è¬å¼µå¡ç‰‡
   - æ”¯æ´ GPU åŠ é€Ÿ

---

## ğŸ”§ æŠ€è¡“å¯¦ä½œ

### Step 1: å»ºç«‹å¡ç‰‡å‘é‡è³‡æ–™åº«

```python
# card_embedding_builder.py
import torch
import clip
from PIL import Image
from pymilvus import connections, Collection, FieldSchema, CollectionSchema, DataType

class CardEmbeddingBuilder:
    def __init__(self):
        # è¼‰å…¥ CLIP æ¨¡å‹
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.model, self.preprocess = clip.load("ViT-B/32", device=self.device)
        
        # é€£æ¥ Milvus
        connections.connect("default", host="localhost", port="19530")
    
    def extract_embedding(self, image_path: str) -> list:
        """æå–å¡ç‰‡åœ–åƒçš„ç‰¹å¾µå‘é‡"""
        image = Image.open(image_path)
        image_input = self.preprocess(image).unsqueeze(0).to(self.device)
        
        with torch.no_grad():
            image_features = self.model.encode_image(image_input)
            # æ­£è¦åŒ–å‘é‡
            image_features /= image_features.norm(dim=-1, keepdim=True)
        
        return image_features.cpu().numpy()[0].tolist()
    
    def build_index(self, cards_data: list):
        """å»ºç«‹å¡ç‰‡å‘é‡ç´¢å¼•"""
        # å®šç¾© Collection Schema
        fields = [
            FieldSchema(name="card_id", dtype=DataType.INT64, is_primary=True),
            FieldSchema(name="card_number", dtype=DataType.VARCHAR, max_length=50),
            FieldSchema(name="game_type", dtype=DataType.VARCHAR, max_length=10),
            FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=512)
        ]
        schema = CollectionSchema(fields, "Card Image Embeddings")
        collection = Collection("card_embeddings", schema)
        
        # æ‰¹é‡æ’å…¥å‘é‡
        for card in cards_data:
            embedding = self.extract_embedding(card["image_path"])
            collection.insert([
                [card["id"]],
                [card["card_number"]],
                [card["game_type"]],
                [embedding]
            ])
        
        # å»ºç«‹ HNSW ç´¢å¼• (é«˜æ•ˆè¿‘ä¼¼æœ€è¿‘é„°æœå°‹)
        index_params = {
            "metric_type": "IP",  # å…§ç© (Inner Product)
            "index_type": "HNSW",
            "params": {"M": 16, "efConstruction": 256}
        }
        collection.create_index("embedding", index_params)
        collection.load()
        
        return collection
```

### Step 2: å¡ç‰‡è­˜åˆ¥ API

```python
# card_recognizer.py
from fastapi import FastAPI, UploadFile, File
from pydantic import BaseModel
from typing import List
import torch
import clip
from PIL import Image
from pymilvus import connections, Collection
import io

class RecognitionResult(BaseModel):
    card_id: int
    card_number: str
    game_type: str
    similarity: float
    name: str
    price_buy: int
    price_sell: int

class CardRecognizer:
    def __init__(self):
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.model, self.preprocess = clip.load("ViT-B/32", device=self.device)
        
        connections.connect("default", host="localhost", port="19530")
        self.collection = Collection("card_embeddings")
        self.collection.load()
    
    def recognize(self, image_bytes: bytes, top_k: int = 5) -> List[dict]:
        """è­˜åˆ¥å¡ç‰‡ï¼Œè¿”å› Top-K æœ€ç›¸ä¼¼çµæœ"""
        # è½‰æ›åœ–åƒ
        image = Image.open(io.BytesIO(image_bytes)).convert("RGB")
        image_input = self.preprocess(image).unsqueeze(0).to(self.device)
        
        # æå–ç‰¹å¾µå‘é‡
        with torch.no_grad():
            image_features = self.model.encode_image(image_input)
            image_features /= image_features.norm(dim=-1, keepdim=True)
        
        query_vector = image_features.cpu().numpy()[0].tolist()
        
        # å‘é‡ç›¸ä¼¼åº¦æœå°‹
        search_params = {"metric_type": "IP", "params": {"ef": 128}}
        results = self.collection.search(
            data=[query_vector],
            anns_field="embedding",
            param=search_params,
            limit=top_k,
            output_fields=["card_id", "card_number", "game_type"]
        )
        
        # æ ¼å¼åŒ–çµæœ
        matches = []
        for hit in results[0]:
            matches.append({
                "card_id": hit.entity.get("card_id"),
                "card_number": hit.entity.get("card_number"),
                "game_type": hit.entity.get("game_type"),
                "similarity": hit.distance  # ç›¸ä¼¼åº¦åˆ†æ•¸ (0-1)
            })
        
        return matches

# FastAPI ç«¯é»
app = FastAPI()
recognizer = CardRecognizer()

@app.post("/api/v2/recognize-card", response_model=List[RecognitionResult])
async def recognize_card(file: UploadFile = File(...)):
    """
    V2 ç‰ˆå¡ç‰‡è­˜åˆ¥ API
    ä½¿ç”¨ CLIP + Milvus å‘é‡æœå°‹
    """
    image_bytes = await file.read()
    matches = recognizer.recognize(image_bytes, top_k=5)
    
    # å¾ PostgreSQL ç²å–è©³ç´°è³‡è¨Š
    results = []
    for match in matches:
        # æŸ¥è©¢å¡ç‰‡è©³ç´°è³‡è¨Šå’Œåƒ¹æ ¼
        card_info = get_card_details(match["card_id"])  # ä½ ç¾æœ‰çš„è³‡æ–™åº«æŸ¥è©¢
        results.append(RecognitionResult(
            **match,
            name=card_info["name"],
            price_buy=card_info["buy_price"],
            price_sell=card_info["sell_price"]
        ))
    
    return results
```

### Step 3: å‰ç«¯æ•´åˆ

```jsx
// AIBuyV2.jsx - æ–°ç‰ˆ AI è²·å–é é¢
import React, { useState, useRef } from 'react';

function AIBuyV2() {
  const [results, setResults] = useState([]);
  const [loading, setLoading] = useState(false);
  const [selectedCard, setSelectedCard] = useState(null);
  const videoRef = useRef(null);

  const handleCapture = async () => {
    setLoading(true);
    
    // å¾ç›¸æ©Ÿæˆ–ä¸Šå‚³ç²å–åœ–ç‰‡
    const canvas = document.createElement('canvas');
    canvas.width = videoRef.current.videoWidth;
    canvas.height = videoRef.current.videoHeight;
    canvas.getContext('2d').drawImage(videoRef.current, 0, 0);
    
    const blob = await new Promise(resolve => canvas.toBlob(resolve, 'image/jpeg', 0.9));
    const formData = new FormData();
    formData.append('file', blob, 'card.jpg');
    
    try {
      const response = await fetch('/api/v2/recognize-card', {
        method: 'POST',
        body: formData
      });
      const data = await response.json();
      setResults(data);
    } catch (error) {
      console.error('è­˜åˆ¥å¤±æ•—:', error);
    }
    
    setLoading(false);
  };

  return (
    <div className="ai-buy-v2">
      <div className="camera-section">
        <video ref={videoRef} autoPlay playsInline />
        <button onClick={handleCapture} disabled={loading}>
          {loading ? 'è­˜åˆ¥ä¸­...' : 'ğŸ“· æ‹æ”è­˜åˆ¥'}
        </button>
      </div>
      
      <div className="results-section">
        <h3>è­˜åˆ¥çµæœ (Top 5)</h3>
        {results.map((result, index) => (
          <div 
            key={result.card_id}
            className={`result-card ${selectedCard?.card_id === result.card_id ? 'selected' : ''}`}
            onClick={() => setSelectedCard(result)}
          >
            <span className="rank">#{index + 1}</span>
            <span className="similarity">{(result.similarity * 100).toFixed(1)}%</span>
            <span className="card-number">{result.card_number}</span>
            <span className="name">{result.name}</span>
            <span className="price">Â¥{result.price_buy}</span>
          </div>
        ))}
      </div>
      
      {selectedCard && (
        <div className="confirm-section">
          <h3>ç¢ºèªå¡ç‰‡</h3>
          <p>{selectedCard.card_number} - {selectedCard.name}</p>
          <button onClick={() => addToBuyList(selectedCard)}>
            âœ… åŠ å…¥è²·å–å–®
          </button>
        </div>
      )}
    </div>
  );
}
```

---

## ğŸ“Š æŒçºŒå­¸ç¿’æ©Ÿåˆ¶

### 1. ç”¨æˆ¶å›é¥‹å­¸ç¿’

```python
# feedback_learning.py
class FeedbackLearner:
    """
    æ”¶é›†ç”¨æˆ¶ç¢ºèª/ä¿®æ­£çš„çµæœ
    ç”¨æ–¼å¾®èª¿æ¨¡å‹å’Œæ”¹å–„è­˜åˆ¥
    """
    
    def record_feedback(self, image_hash: str, predicted: str, corrected: str):
        """
        è¨˜éŒ„ç”¨æˆ¶çš„ä¿®æ­£è¡Œç‚º
        - image_hash: åœ–ç‰‡å“ˆå¸Œå€¼
        - predicted: ç³»çµ±é æ¸¬çš„å¡è™Ÿ
        - corrected: ç”¨æˆ¶ä¿®æ­£å¾Œçš„å¡è™Ÿ (None è¡¨ç¤ºé æ¸¬æ­£ç¢º)
        """
        if corrected and predicted != corrected:
            # å„²å­˜éŒ¯èª¤æ¡ˆä¾‹ç”¨æ–¼å¾ŒçºŒåˆ†æ
            self.save_error_case(image_hash, predicted, corrected)
            
            # æ›´æ–°å¡ç‰‡çš„ç‰¹å¾µå‘é‡ (å¢å¼·å­¸ç¿’)
            self.update_embedding_weight(corrected, boost=1.2)
    
    def retrain_monthly(self):
        """
        æ¯æœˆåŸºæ–¼æ”¶é›†çš„å›é¥‹æ•¸æ“šå¾®èª¿æ¨¡å‹
        """
        error_cases = self.load_error_cases()
        if len(error_cases) > 100:
            # ä½¿ç”¨å°æ¯”å­¸ç¿’å¾®èª¿ CLIP
            self.finetune_clip(error_cases)
```

### 2. æ–°å¡è‡ªå‹•å…¥åº«

```python
# auto_indexer.py
class AutoCardIndexer:
    """
    ç•¶çˆ¬èŸ²æŠ“å–åˆ°æ–°å¡è³‡æ–™æ™‚
    è‡ªå‹•ä¸‹è¼‰å¡åœ–ä¸¦å»ºç«‹å‘é‡ç´¢å¼•
    """
    
    async def index_new_cards(self, new_cards: list):
        for card in new_cards:
            # ä¸‹è¼‰å¡åœ–
            image_path = await self.download_card_image(card["image_url"])
            
            # æå–å‘é‡
            embedding = self.embedding_builder.extract_embedding(image_path)
            
            # æ’å…¥å‘é‡è³‡æ–™åº«
            self.collection.insert([
                [card["id"]],
                [card["card_number"]],
                [card["game_type"]],
                [embedding]
            ])
        
        # é‡å»ºç´¢å¼•
        self.collection.release()
        self.collection.load()
```

---

## ğŸ› ï¸ éƒ¨ç½²éœ€æ±‚

### ç¡¬é«”éœ€æ±‚

| çµ„ä»¶ | æœ€ä½é…ç½® | æ¨è–¦é…ç½® |
|:---|:---|:---|
| CPU | 4 æ ¸å¿ƒ | 8 æ ¸å¿ƒ |
| RAM | 8 GB | 16 GB |
| GPU | ç„¡ (CPU æ¨ç†) | NVIDIA GTX 1060+ |
| å„²å­˜ | 50 GB SSD | 100 GB SSD |

### è»Ÿé«”ä¾è³´

```bash
# requirements.txt
torch>=2.0.0
clip-by-openai
Pillow>=9.0.0
pymilvus>=2.3.0
fastapi>=0.100.0
uvicorn>=0.22.0
```

### Docker éƒ¨ç½²

```yaml
# docker-compose.yml
version: '3.8'

services:
  milvus:
    image: milvusdb/milvus:v2.3.0
    ports:
      - "19530:19530"
    volumes:
      - milvus_data:/var/lib/milvus
    environment:
      ETCD_ENDPOINTS: etcd:2379
      MINIO_ADDRESS: minio:9000

  etcd:
    image: quay.io/coreos/etcd:v3.5.0

  minio:
    image: minio/minio:latest
    environment:
      MINIO_ACCESS_KEY: minioadmin
      MINIO_SECRET_KEY: minioadmin

  card-recognizer:
    build: ./backend
    ports:
      - "8001:8000"
    depends_on:
      - milvus
    environment:
      MILVUS_HOST: milvus
      MILVUS_PORT: 19530

volumes:
  milvus_data:
```

---

## ğŸ“ˆ é æœŸæ•ˆæœ

| æŒ‡æ¨™ | ç•¶å‰ v4.0 | é æœŸ v5.0 (CLIP) |
|:---|:---:|:---:|
| è­˜åˆ¥æº–ç¢ºç‡ | ~60% | 95%+ |
| è­˜åˆ¥é€Ÿåº¦ | 2-3 ç§’ | <500ms |
| æ”¯æ´ç‰ˆæœ¬å€åˆ† | âŒ | âœ… (ç•°åœ–/æ™®å¡) |
| å…‰ç·šé©æ‡‰æ€§ | å¼± | å¼· |
| è§’åº¦å®¹éŒ¯ | å¼± | ä¸­ç­‰ |

---

## ğŸ—“ï¸ å¯¦æ–½è·¯ç·šåœ–

### Phase 1 (ç¬¬ 1 é€±)
- [ ] å®‰è£ Milvus å‘é‡è³‡æ–™åº«
- [ ] ä¸‹è¼‰æ‰€æœ‰å¡ç‰‡åœ–ç‰‡ (ç´„ 24,000 å¼µ)
- [ ] å»ºç«‹åˆå§‹å‘é‡ç´¢å¼•

### Phase 2 (ç¬¬ 2 é€±)
- [ ] é–‹ç™¼ v2 è­˜åˆ¥ API
- [ ] æ•´åˆå‰ç«¯ AIBuy é é¢
- [ ] å…§éƒ¨æ¸¬è©¦

### Phase 3 (ç¬¬ 3-4 é€±)
- [ ] æ”¶é›†ç”¨æˆ¶å›é¥‹
- [ ] å„ªåŒ–è­˜åˆ¥é‚Šç·£æ¡ˆä¾‹
- [ ] æ­£å¼ä¸Šç·š

---

## ğŸ’¡ é€²éšå„ªåŒ– (æœªä¾†)

1. **å¤šè¦–è§’è­˜åˆ¥**
   - æ”¯æ´å¡ç‰‡æ­£é¢/èƒŒé¢
   - æ”¯æ´å¤šå¼µå¡ç‰‡æ‰¹é‡è­˜åˆ¥

2. **æ¢ç¢¼è¼”åŠ©**
   - çµåˆæ¢ç¢¼æƒææé«˜æº–ç¢ºåº¦
   - æ¢ç¢¼ â†’ å¡è™Ÿ â†’ å‘é‡é©—è­‰

3. **æœ¬åœ°é›¢ç·šæ¨¡å‹**
   - å°‡æ¨¡å‹è¼•é‡åŒ– (MobileNet + ONNX)
   - æ”¯æ´é›¢ç·šä½¿ç”¨

---

## â“ å¸¸è¦‹å•é¡Œ

**Q: éœ€è¦ GPU å—ï¼Ÿ**
A: ä¸éœ€è¦ã€‚CPU æ¨ç†é€Ÿåº¦ç´„ 200-500msï¼Œè¶³å¤ ä½¿ç”¨ã€‚GPU å¯åŠ é€Ÿè‡³ 50msã€‚

**Q: å¦‚ä½•è™•ç†ç›¸ä¼¼å¡ç‰‡ (åŒå¡ä¸åŒç‰ˆæœ¬)ï¼Ÿ**
A: CLIP å¯ä»¥å€åˆ†ç´°å¾®å·®ç•°ã€‚å°æ–¼æ¥µç›¸ä¼¼çš„å¡ç‰‡ï¼Œè¿”å› Top-5 è®“ç”¨æˆ¶é¸æ“‡ã€‚

**Q: è¨“ç·´éœ€è¦å¤šå°‘æ•¸æ“šï¼Ÿ**
A: **ä¸éœ€è¦è¨“ç·´**ï¼CLIP æ˜¯é è¨“ç·´æ¨¡å‹ï¼Œç›´æ¥ä½¿ç”¨ã€‚æˆ‘å€‘åªéœ€å»ºç«‹åœ–ç‰‡å‘é‡åº«ã€‚

**Q: æˆæœ¬å¤šå°‘ï¼Ÿ**
A: 
- Milvus: é–‹æºå…è²»
- ä¼ºæœå™¨: ç´„ $50-100/æœˆ (é›²ç«¯)
- ç„¡ API èª¿ç”¨è²»ç”¨

---

## ğŸ“š åƒè€ƒè³‡æ–™

- [OpenAI CLIP è«–æ–‡](https://arxiv.org/abs/2103.00020)
- [Milvus å®˜æ–¹æ–‡æª”](https://milvus.io/docs)
- [Pinecone Image Search æ•™ç¨‹](https://www.pinecone.io/learn/series/image-search/)
- [eBay åœ–åƒè­˜åˆ¥æŠ€è¡“åšå®¢](https://tech.ebayinc.com/)
