# =========================================================
# Phase 1, Block 3.1: åƒ¹æ ¼çˆ¬èŸ² (Price Scraper) - Card Rush VG å”®åƒ¹ v1.5 (é‡è©¦æ©Ÿåˆ¶ + æ‰¹æ¬¡å¯«å…¥)
# Author: é›»ç‹
# æˆ°è¡“: ã€v1.2 é›™é‡æƒæã€‘+ã€v1.3 JPY-Only + API å„ªåŒ–ã€‘+ã€v1.4 é‡è©¦æ©Ÿåˆ¶ã€‘
# Update: v1.5 - æ–°å¢æ‰¹æ¬¡å¯«å…¥æ©Ÿåˆ¶ï¼Œé™ä½é•·ç¨‹åŸ·è¡Œæ™‚çš„è³‡æ–™éºå¤±é¢¨éšªã€‚
# Update: v1.4 - æ–°å¢é é¢é‡è©¦æ©Ÿåˆ¶ + ç€è¦½å™¨å®šæœŸé‡å•Ÿï¼Œè§£æ±ºé€£æ¥ä¸­æ–·å•é¡Œ
# Update: v1.3 - å¾¹åº•ç§»é™¤æ‰€æœ‰åŒ¯ç‡ (HKD) ç›¸é—œä»£ç¢¼ã€‚
#         æ­¤è…³æœ¬ç¾åœ¨åªè² è²¬æŠ“å– JPY åŸå§‹åƒ¹æ ¼ä¸¦å¯«å…¥ Sheet (9æ¬„çµæ§‹)ã€‚
#         ã€æ ¸å¿ƒã€‘: å°‡ get_all_records() æ›¿æ›ç‚º col_values(2)ï¼Œ
#                   è§£æ±ºå›  Card_Master éå¤§å°è‡´çš„ APIError: [500] éŒ¯èª¤ã€‚
# =========================================================
import gspread
from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import InstalledAppFlow
from google.auth.transport.requests import Request
import os.path, time, re, random, sys
from datetime import datetime
from bs4 import BeautifulSoup
import pandas as pd
from playwright.sync_api import sync_playwright, TimeoutError as PlaywrightTimeoutError


def log(message: str):
    print(message)
    sys.stdout.flush()
# import requests # <-- ã€v1.2ã€‘ å·²ç§»é™¤

# --- [æ­¥é©Ÿ A: æœ¬åœ°ç«¯ Google Sheets æˆæ¬Š] --- 
print(">> æ­¥é©Ÿ A: æ­£åœ¨é€²è¡Œæœ¬åœ°ç«¯ Google Sheets æˆæ¬Š...")
SCOPES = ['https://www.googleapis.com/auth/spreadsheets', 'https://www.googleapis.com/auth/drive']
creds = None
# ... (æˆæ¬Šä»£ç¢¼ä¸è®Š) ...
if os.path.exists('token.json'): creds = Credentials.from_authorized_user_file('token.json', SCOPES)
if not creds or not creds.valid:
    if creds and creds.expired and creds.refresh_token:
        try: creds.refresh(Request())
        except Exception as e:
            print(f"âŒ åˆ·æ–° Token å¤±æ•—: {e}");
            if os.path.exists('credentials.json'):
                flow = InstalledAppFlow.from_client_secrets_file('credentials.json', SCOPES); creds = flow.run_local_server(port=0)
            else: print("\nâŒ éŒ¯èª¤: æ‰¾ä¸åˆ° 'credentials.json'ã€‚"); sys.exit(1)
    else:
        if not os.path.exists('credentials.json'): print("\nâŒ éŒ¯èª¤: æ‰¾ä¸åˆ° 'credentials.json'ã€‚"); sys.exit(1)
        flow = InstalledAppFlow.from_client_secrets_file('credentials.json', SCOPES); creds = flow.run_local_server(port=0)
    with open('token.json', 'w') as token: token.write(creds.to_json())
gc = gspread.authorize(creds)
print("âœ… Google Sheets æˆæ¬ŠæˆåŠŸã€‚")

# --- [VG è¨­å®šå€åŸŸ] ---
sheet_name = "å¡ç‰Œåƒ¹æ ¼è¿½è¹¤ç³»çµ± - Command Deck"
master_worksheet_name = "Card_Master"
history_worksheet_name = "Price_History"
website_name = "Cardrush-Vanguard"
base_url = "https://www.cardrush-vanguard.jp"
game_title = "Vanguard"
SERIES_INDEX_URL_1 = "https://www.cardrush-vanguard.jp/" 
SERIES_INDEX_URL_2 = "https://www.cardrush-vanguard.jp/page/47" 

# --- [v1.5] æ‰¹æ¬¡å¯«å…¥è¨­å®š ---
MASTER_BATCH_SIZE = 100
HISTORY_BATCH_SIZE = 200

# --- ã€v1.3ã€‘ åŒ¯ç‡æ›ç®—å‡½æ•¸å·²ç§»é™¤ --- 

# --- [v1.4 æ–°å¢ï¼šå¸¶é‡è©¦æ©Ÿåˆ¶çš„é é¢è¨ªå•å‡½æ•¸] ---
def retry_page_goto(page, url, max_retries=3):
    """å¸¶é‡è©¦æ©Ÿåˆ¶çš„é é¢è¨ªå•"""
    for attempt in range(max_retries):
        try:
            page.goto(url, wait_until='networkidle', timeout=30000)
            page.wait_for_selector("li.list_item_cell", timeout=10000)
            return True
        except Exception as e:
            print(f"     -> âš ï¸ è¨ªå•å¤±æ•— (å˜—è©¦ {attempt+1}/{max_retries}): {str(e)[:80]}...")
            if attempt < max_retries - 1:
                wait_time = random.uniform(3, 6)
                print(f"     -> ç­‰å¾… {wait_time:.1f} ç§’å¾Œé‡è©¦...")
                time.sleep(wait_time)
            else:
                print(f"     -> âŒ é é¢é‡è©¦ {max_retries} æ¬¡å¾Œä»å¤±æ•—")
                return False
    return False

# --- [v1.2 å‡½æ•¸] ---
def get_links_from_page(page, url, selector):
    print(f" Â  Â  -> æ­£åœ¨è¨ªå•: {url}...")
    try:
        page.goto(url, wait_until='networkidle', timeout=60000)
        page.wait_for_selector(selector, timeout=15000)
        html = page.content()
        soup = BeautifulSoup(html, 'html.parser')
        links = []
        series_links = soup.select(selector)
        for link in series_links:
            href = link.get('href')
            if href and ('/product-group/' in href):
                if href.startswith(base_url): href = href.replace(base_url, "") 
                href_without_params = href.split('?')[0] # ç§»é™¤åƒæ•¸
                if href_without_params not in links:
                    links.append(href_without_params) 
        print(f" Â  Â  -> âœ… åœ¨ {url} ç™¼ç¾ {len(links)} å€‹ç³»åˆ—é€£çµã€‚")
        return links
    except Exception as e:
        print(f" Â  Â  -> âŒ æƒæ {url} æ™‚å¤±æ•—: {e}")
        return []

# --- [ä¸»ç¨‹å¼é–‹å§‹] ---
try:
    print(f"\n>> åƒ¹æ ¼çˆ¬èŸ² v1.5 ({website_name} å”®åƒ¹ - JPY-Only + é‡è©¦ + æ‰¹æ¬¡å¯«å…¥) å·²å•Ÿå‹•...")
    print(">> æ­¥é©Ÿ 1/5: æ­£åœ¨è®€å– `Card_Master` (å„ªåŒ–æ¨¡å¼)...") # æ­¥é©Ÿé‡ç·¨
    master_worksheet = gc.open(sheet_name).worksheet(master_worksheet_name)
    history_worksheet = gc.open(sheet_name).worksheet(history_worksheet_name)
    
    # --- ã€v1.3 API å„ªåŒ–ã€‘ ---
    print(" Â  Â  -> æ­£åœ¨è®€å– Card_Number (B æ¬„)...")
    all_card_numbers = master_worksheet.col_values(2) 
    existing_card_numbers = set(all_card_numbers[1:]) 
    print(f"âœ… è®€å–æˆåŠŸï¼Œè³‡æ–™åº«ä¸­ç¾æœ‰ {len(existing_card_numbers)} æ¢å¡è™Ÿç´€éŒ„ä»¥ä¾›åƒè€ƒã€‚")
    # --- ã€å„ªåŒ–çµæŸã€‘ ---

    # --- ã€v1.3ã€‘ æ­¥é©Ÿ 2 (ç²å–åŒ¯ç‡) å·²ç§»é™¤ ---

    with sync_playwright() as p:
        print("\n>> æ­¥é©Ÿ 2/5: æ­£åœ¨å•Ÿå‹• Playwright ç€è¦½å™¨...") # æ­¥é©Ÿé‡ç·¨
        browser = p.firefox.launch(headless=True) 
        page = browser.new_page()
        print("âœ… Playwright ç€è¦½å™¨æº–å‚™å°±ç·’ã€‚")

        print("\n>> æ­¥é©Ÿ 3/5: é–‹å§‹é›™é‡å‹•æ…‹æƒæ VG ç³»åˆ—å°ˆæ«ƒ...") # æ­¥é©Ÿé‡ç·¨
        
        links_from_main = get_links_from_page(page, SERIES_INDEX_URL_1, "section.pickupcategory_division1 ul.pickupcategory_list li a")
        links_from_theme = get_links_from_page(page, SERIES_INDEX_URL_2, "div.mtgdekkitema a")
        
        VG_SERIES_URLS = list(set(links_from_main + links_from_theme))
        
        if not VG_SERIES_URLS:
            print("âŒ éŒ¯èª¤: æœªèƒ½ç²å–ä»»ä½• VG ç³»åˆ— URLï¼Œä»»å‹™ä¸­æ­¢ã€‚")
            browser.close(); exit()
            
        print(f"âœ… é›™é‡æƒæå®Œç•¢ï¼Œå…±ç™¼ç¾ {len(VG_SERIES_URLS)} å€‹ç¨ç«‹ç³»åˆ—å°ˆæ«ƒã€‚")
        all_cardrush_cards = {}

        for i, series_url_path in enumerate(VG_SERIES_URLS):
            # --- [v1.4 æ–°å¢ï¼šæ¯ 15 å€‹å°ˆæ«ƒé‡å•Ÿç€è¦½å™¨] ---
            if i > 0 and i % 15 == 0:
                print(f"\n  -> ğŸ”„ å·²æƒæ {i} å€‹å°ˆæ«ƒï¼Œé‡å•Ÿç€è¦½å™¨ä»¥é‡‹æ”¾è³‡æº...")
                try:
                    page.close()
                    browser.close()
                    time.sleep(3)
                    browser = p.firefox.launch(headless=True)
                    page = browser.new_page()
                    print("  -> âœ… ç€è¦½å™¨å·²é‡å•Ÿ\n")
                except Exception as e:
                    print(f"  -> âš ï¸ ç€è¦½å™¨é‡å•Ÿå¤±æ•—: {e}ï¼Œå˜—è©¦ç¹¼çºŒ...")
            
            series_url = base_url + series_url_path
            print(f"  -> æ­£åœ¨æƒè•©å°ˆæ«ƒ {i+1}/{len(VG_SERIES_URLS)}: {series_url}")
            
            current_page = 1
            consecutive_failures = 0  # [v1.4] é€£çºŒå¤±æ•—è¨ˆæ•¸å™¨
            
            while True:
                page_url = f"{series_url}?page={current_page}"
                if current_page == 1: page_url = series_url

                print(f"     -> æ­£åœ¨æƒè•©é é¢ {current_page}...")
                
                # --- [v1.4 æ ¸å¿ƒæ”¹å‹•ï¼šä½¿ç”¨é‡è©¦å‡½æ•¸] ---
                if not retry_page_goto(page, page_url):
                    consecutive_failures += 1
                    
                    # é€£çºŒå¤±æ•— 2 æ¬¡ï¼Œå˜—è©¦é‡å•Ÿç€è¦½å™¨
                    if consecutive_failures == 2:
                        print(f"     -> ğŸ”„ é€£çºŒå¤±æ•— {consecutive_failures} æ¬¡ï¼Œå˜—è©¦é‡å•Ÿç€è¦½å™¨...")
                        try:
                            page.close()
                            browser.close()
                            time.sleep(5)
                            browser = p.firefox.launch(headless=True)
                            page = browser.new_page()
                            print("     -> âœ… ç€è¦½å™¨å·²é‡å•Ÿï¼Œç¹¼çºŒå˜—è©¦...")
                            consecutive_failures = 0
                            continue  # é‡æ–°å˜—è©¦ç•¶å‰é é¢
                        except Exception as e:
                            print(f"     -> âŒ ç€è¦½å™¨é‡å•Ÿå¤±æ•—: {e}")
                    
                    # é€£çºŒå¤±æ•— 3 æ¬¡ï¼Œæ”¾æ£„è©²å°ˆæ«ƒ
                    if consecutive_failures >= 3:
                        print("     -> âš ï¸ é€£çºŒå¤±æ•—éå¤šï¼Œè·³è½‰åˆ°ä¸‹å€‹å°ˆæ«ƒ")
                        break
                    
                    current_page += 1
                    continue
                
                consecutive_failures = 0  # æˆåŠŸå¾Œé‡ç½®å¤±æ•—è¨ˆæ•¸
                
                try:
                    page_html = page.content()
                    soup = BeautifulSoup(page_html, 'html.parser')
                    card_items = soup.select("li.list_item_cell")
                    if not card_items: 
                        print("     -> æ­¤é é¢æ²’æœ‰å•†å“ï¼Œå¯èƒ½å·²åˆ°é”æœ«é ")
                        break
                    print(f"     -> åœ¨æ­¤é é¢ç™¼ç¾ {len(card_items)} å€‹å•†å“ã€‚")

                    for item in card_items:
                        item_data = item.find('div', class_='item_data');
                        if not item_data: continue
                        name_tag = item.find('span', class_='goods_name'); 
                        price_tag = item.find('span', class_='figure'); 
                        stock_tag = item.find('p', class_='stock')
                        if not name_tag or not price_tag: continue
                        
                        item_name = name_tag.text.strip()
                        price_jpy = int(re.sub(r'[^\d]', '', price_tag.text))

                        status = "In Stock"
                        if (stock_tag and "soldout" in stock_tag.get('class', [])) or \
                           (stock_tag and "SOLD OUT" in stock_tag.text) or (stock_tag and "å“åˆ‡ã‚Œ" in stock_tag.text) or \
                           'soldout' in item.get('class', []):
                            status = "Out of Stock"

                        item_card_number = ""
                        vg_regex = r'\{([A-Z0-9/_-]+)\}' 
                        match_num = re.search(vg_regex, item_name)
                        if match_num:
                            item_card_number = match_num.group(1).strip()
                        else:
                            continue 

                        image_url = ""
                        image_tag = item.select_one("div.global_photo img")
                        if image_tag and image_tag.has_attr('src'):
                            image_url = image_tag['src'].strip()
                            # URL æ¸…æ½” (ç¹¼æ‰¿ v1.0)
                            image_url = re.sub(r'\s+', '%20', image_url) 
                            image_url = image_url.replace('/ ', '/') 
                            if image_url.startswith('//'): image_url = 'https:' + image_url
                            
                        all_cardrush_cards[(item_card_number, item_name)] = {'price_jpy': price_jpy, 'status': status, 'image_url': image_url}

                    next_page_link = soup.select_one('a.to_next_page')
                    if not next_page_link: 
                        print("     -> æ­¤ç³»åˆ—å·²æƒè•©å®Œç•¢ï¼ˆæ²’æœ‰ä¸‹ä¸€é ï¼‰ã€‚"); 
                        break
                    
                    current_page += 1
                    wait_time = random.uniform(2, 5)  # [v1.4] å¢åŠ å»¶é²ç¯„åœ
                    time.sleep(wait_time)
                    
                except Exception as e: 
                    print(f"     -> âŒ è§£æé é¢ {current_page} æ™‚å¤±æ•—: {e}"); 
                    consecutive_failures += 1
                    if consecutive_failures >= 3:
                        print("     -> é€£çºŒè§£æå¤±æ•—éå¤šï¼Œè·³è½‰åˆ°ä¸‹å€‹å°ˆæ«ƒ")
                        break
                    continue

        print(f"\nâœ… æ‰€æœ‰ VG å°ˆæ«ƒæƒè•©å®Œç•¢ï¼Œå…±æ•ç² {len(all_cardrush_cards)} ç¨®å¡ç‰Œçš„æƒ…å ±ã€‚")

        print("\n>> æ­¥é©Ÿ 4/5: é–‹å§‹åŸ·è¡Œæƒ…å ±æ“´å¼µ (VG) èˆ‡åƒ¹æ ¼è¨˜éŒ„...") # æ­¥é©Ÿé‡ç·¨
        new_cards_to_add = []
        price_history_to_add = []
        total_new_cards = 0
        total_price_records = 0
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        def flush_new_cards(force=False):
            if new_cards_to_add and (force or len(new_cards_to_add) >= MASTER_BATCH_SIZE):
                log(f"     -> æ­£åœ¨æ‰¹æ¬¡å¯«å…¥ {len(new_cards_to_add)} å¼µæ–° VG å¡ç‰Œè‡³ `Card_Master`...")
                master_worksheet.append_rows(new_cards_to_add, value_input_option='USER_ENTERED')
                log("     -> âœ… æ–° VG å¡ç‰Œæ‰¹æ¬¡å¯«å…¥å®Œæˆï¼")
                new_cards_to_add.clear()

        def flush_price_history(force=False):
            if price_history_to_add and (force or len(price_history_to_add) >= HISTORY_BATCH_SIZE):
                log(f"     -> æ­£åœ¨æ‰¹æ¬¡å¯«å…¥ {len(price_history_to_add)} æ¢ VG å”®åƒ¹è‡³ `Price_History`...")
                price_history_to_add.sort(key=lambda record: (record[1], record[5]))
                history_worksheet.append_rows(price_history_to_add, value_input_option='USER_ENTERED')
                log("     -> âœ… VG å”®åƒ¹æ‰¹æ¬¡å¯«å…¥å®Œæˆï¼")
                price_history_to_add.clear()

        for (item_card_number, item_name), card_info in all_cardrush_cards.items():
            price_jpy = card_info['price_jpy']; status = card_info['status']; image_url = card_info['image_url']
            # --- ã€v1.3ã€‘ price_hkd å·²ç§»é™¤ ---

            # --- [æƒ…å ±æ“´å¼µ: Card_Master] ---
            if item_card_number not in existing_card_numbers:
                print(f" Â  Â  -> âœ¨ ç™¼ç¾æ–° VG å¡ç‰Œï¼ {item_card_number} {item_name}")
                rarity = "Unknown"; card_type = "Unknown"
                rarity_match = re.search(r'ã€([A-Zâ˜…]+)ã€‘', item_name) 
                if rarity_match: rarity = rarity_match.group(1)
                type_match = re.search(r'ã€Š([^ã€‹]+)ã€‹', item_name) 
                if type_match: card_type = type_match.group(1)
                set_id = item_card_number.split('/')[0] if '/' in item_card_number else "VG_Unknown"
                unique_id = f"{item_card_number}_{rarity}"
                
                new_cards_to_add.append([
                    unique_id, item_card_number, game_title, set_id,
                    item_name, rarity, image_url, card_type
                ])
                # existing_cards_map removed
                existing_card_numbers.add(item_card_number)
                total_new_cards += 1
                print(f" Â  Â  Â  -> å·²æº–å‚™å°‡å…¶æ·»åŠ åˆ° `Card_Master`ã€‚")
                flush_new_cards()

            # --- [åƒ¹æ ¼è¨˜éŒ„: Price_History] ---
            history_unique_id = f"{item_card_number}_{item_name}"
            history_id = f"{history_unique_id}_{website_name}_{timestamp}"
            set_id_history = item_card_number.split('/')[0] if '/' in item_card_number else "VG_Unknown"

            # --- ã€v1.3 JPY-Only çµæ§‹ (9 æ¬„)ã€‘ ---
            price_history_to_add.append([
                history_id, history_unique_id, website_name,
                price_jpy,  # D: Sell_Price_JPY
                "N/A",      # E: Buy_Price_JPY
                timestamp,  # F: Timestamp
                status,     # G: Status
                set_id_history, # H: Set_ID
                image_url   # I: Image_URL
            ])
            total_price_records += 1
            flush_price_history()

            if total_price_records % 150 == 0:
                log(f"     -> å·²è™•ç† {total_price_records} ç­† VG å”®åƒ¹è³‡æ–™ (ç›®å‰ç´¯ç© {len(price_history_to_add)} ç­†å¾…å¯«å…¥)ã€‚")

        log(f"\nâœ… æƒ…å ±è™•ç†å®Œç•¢ã€‚å…±åµæ¸¬ {total_new_cards} å¼µæ–° VG å¡ç‰Œï¼Œè¨˜éŒ„ {total_price_records} æ¢ VG åƒ¹æ ¼æƒ…å ± (JPY)ã€‚")

        log("\n>> æ­¥é©Ÿ 5/5: æ­£åœ¨è§¸ç™¼æœ€çµ‚æ‰¹æ¬¡å¯«å…¥ (VG å”®åƒ¹)...") # æ­¥é©Ÿé‡ç·¨

        flush_new_cards(force=True)
        if total_new_cards == 0:
            log("     -> æœªç™¼ç¾éœ€è¦æ·»åŠ åˆ° `Card_Master` çš„æ–° VG å¡ç‰Œã€‚")
        else:
            log(f"     -> âœ… ç´¯è¨ˆå¯«å…¥ `Card_Master` {total_new_cards} å¼µæ–° VG å¡ç‰Œã€‚")

        flush_price_history(force=True)
        if total_price_records == 0:
            log("     -> æœªæ•ç²åˆ°éœ€è¦æ·»åŠ åˆ° `Price_History` çš„ VG åƒ¹æ ¼æƒ…å ±ã€‚")
        else:
            log(f"     -> âœ… ç´¯è¨ˆå¯«å…¥ `Price_History` {total_price_records} æ¢ VG åƒ¹æ ¼æƒ…å ±ã€‚")

        log("\n\nğŸ‰ğŸ‰ğŸ‰ æ­å–œï¼Card Rush (VG) å”®åƒ¹ (JPY-Only) å¾æœä»»å‹™å®Œæˆï¼ ğŸ‰ğŸ‰ğŸ‰")
        browser.close()

except Exception as e:
    print(f"\nâŒâŒâŒ ç™¼ç”Ÿåš´é‡éŒ¯èª¤ âŒâŒâŒ"); print(f"éŒ¯èª¤è©³æƒ…: {e}")
    if 'browser' in locals() and browser.is_connected(): browser.close()