# =========================================================
# Phase 1, Block 1.2: åƒ¹æ ¼çˆ¬èŸ² (Price Scraper) - Mercadop æ°¸ä¹…ç‰ˆ v3.4
# Author: é›»ç‹
# Update: ã€v3.4 JPY-Only + API å„ªåŒ– + æ–°å‹•æ…‹ URLã€‘
#         1. (ä¾†è‡ª v3.3) ä¿®æ­£ Import éŒ¯èª¤ï¼Œå¾¹åº•ç§»é™¤ HKD ç›¸é—œä»£ç¢¼ã€‚
#         2. (ä¾†è‡ª v3.3) ä½¿ç”¨ col_values(2) å„ªåŒ– API è®€å–ï¼Œè§£æ±º [500] éŒ¯èª¤ã€‚
#         3. ã€æ ¸å¿ƒã€‘: æ”¾æ£„ä¸»é æƒæï¼Œæ”¹ç‚ºå¾ /page/5 (ãƒ‘ãƒƒã‚¯åˆ¥)
#            å‹•æ…‹æŠ“å–æ‰€æœ‰ Booster å’Œ Deck ç³»åˆ—é€£çµã€‚
# =========================================================
import gspread
from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import InstalledAppFlow
from google.auth.transport.requests import Request
import os.path, time, re, random, sys
from datetime import datetime
from bs4 import BeautifulSoup
import pandas as pd
from playwright.sync_api import sync_playwright, TimeoutError as PlaywrightTimeoutError
# import requests # <-- ã€v3.4ã€‘ å·²ç§»é™¤

# --- [æ­¥é©Ÿ A: æœ¬åœ°ç«¯ Google Sheets æˆæ¬Š] ---
print(">> æ­¥é©Ÿ A: æ­£åœ¨é€²è¡Œæœ¬åœ°ç«¯ Google Sheets æˆæ¬Š...")
SCOPES = ['https://www.googleapis.com/auth/spreadsheets', 'https://www.googleapis.com/auth/drive']
creds = None
# ... (æˆæ¬Šä»£ç¢¼ä¸è®Š) ...
if os.path.exists('token.json'): creds = Credentials.from_authorized_user_file('token.json', SCOPES)
if not creds or not creds.valid:
    if creds and creds.expired and creds.refresh_token:
        try: creds.refresh(Request())
        except Exception as e:
            print(f"âŒ åˆ·æ–° Token å¤±æ•—: {e}");
            if os.path.exists('credentials.json'):
                flow = InstalledAppFlow.from_client_secrets_file('credentials.json', SCOPES); creds = flow.run_local_server(port=0)
            else: print("\nâŒ éŒ¯èª¤: æ‰¾ä¸åˆ° 'credentials.json'ã€‚"); sys.exit(1)
    else:
        if not os.path.exists('credentials.json'): print("\nâŒ éŒ¯èª¤: æ‰¾ä¸åˆ° 'credentials.json'ã€‚"); sys.exit(1)
        flow = InstalledAppFlow.from_client_secrets_file('credentials.json', SCOPES); creds = flow.run_local_server(port=0)
    with open('token.json', 'w') as token: token.write(creds.to_json())
gc = gspread.authorize(creds)
print("âœ… Google Sheets æˆæ¬ŠæˆåŠŸã€‚")


# --- [è¨­å®šå€åŸŸ] ---
sheet_name = "å¡ç‰Œåƒ¹æ ¼è¿½è¹¤ç³»çµ± - Command Deck"
master_worksheet_name = "Card_Master"
history_worksheet_name = "Price_History"
website_name = "MercadoP"
base_url = "https://www.mercardop.jp"
game_title = "One Piece Card Game"
# ã€v3.4ã€‘ ç›®æ¨™æ”¹ç‚º Pack/Series é é¢
SERIES_PAGE_URL = "https://www.mercardop.jp/page/5" 

# --- ã€v3.4ã€‘ åŒ¯ç‡æ›ç®—å‡½æ•¸å·²ç§»é™¤ --- 

# --- ã€v3.4ã€‘ æ›´æ–°ï¼šå‹•æ…‹ç²å–ç³»åˆ— URL çš„å‡½æ•¸ ---
def get_series_urls(page, series_page_url):
    """
    å¾ /page/5 (ãƒ‘ãƒƒã‚¯åˆ¥) æŠ“å–æ‰€æœ‰ Booster å’Œ Deck ç³»åˆ—çš„ /product-group/ é€£çµã€‚
    """
    print(f" Â -> æ­£åœ¨æƒæç³»åˆ—é é¢ä»¥ç²å–é€£çµ: {series_page_url}...")
    # ç›®æ¨™é¸æ“‡å™¨: é¸æ“‡ BOOSTER å’Œ DECKS ä¸‹æ–¹çš„æ‰€æœ‰é€£çµ
    selector = "div.cate_navi_wrap ul.cate_navi li.cate_li a.cate_aa" 
    try:
        page.goto(series_page_url, wait_until='networkidle', timeout=60000)
        print(f" Â -> ç­‰å¾…é¸æ“‡å™¨ '{selector}' å‡ºç¾ (æœ€é•· 30 ç§’)...")
        page.wait_for_selector(selector, timeout=30000) 
        print(f" Â -> âœ… é¸æ“‡å™¨å·²æ‰¾åˆ°ã€‚")
        html = page.content()
        soup = BeautifulSoup(html, 'html.parser')
        
        links = []
        # æ‰¾åˆ°æ‰€æœ‰ cate_navi_wrap
        navi_wraps = soup.select("div.cate_navi_wrap")
        
        for wrap in navi_wraps:
            # æª¢æŸ¥æ¨™é¡Œæ˜¯å¦åŒ…å« BOOSTER æˆ– DECKS
            title_tag = wrap.find('h2', class_='cate_navi_ttl')
            if title_tag and ('BOOSTER' in title_tag.text or 'DECKS' in title_tag.text):
                print(f" Â -> æ­£åœ¨è™•ç†å€å¡Š: {title_tag.text.strip()}")
                series_link_tags = wrap.select("ul.cate_navi li.cate_li a.cate_aa")
                for link_tag in series_link_tags:
                    href = link_tag.get('href')
                    if href and ('/product-group/' in href):
                        if href.startswith(base_url): href = href.replace(base_url, "") 
                        href_without_params = href.split('?')[0]
                        if href_without_params not in links:
                            links.append(href_without_params) 
                            
        print(f" Â -> âœ… åœ¨ç³»åˆ—é é¢ç™¼ç¾ {len(links)} å€‹ Booster/Deck ç³»åˆ—é€£çµã€‚")
        return links
        
    except PlaywrightTimeoutError: 
         print(f" Â -> âŒ åœ¨ç³»åˆ—é é¢ç­‰å¾…é¸æ“‡å™¨ '{selector}' è¶…æ™‚ (30ç§’)ã€‚")
         return []
    except Exception as e:
        print(f" Â -> âŒ æƒæç³»åˆ—é é¢ç²å–é€£çµæ™‚å¤±æ•—: {e}")
        return []
# --- ã€v3.4 å‡½æ•¸çµæŸã€‘ ---

# --- [ä¸»ç¨‹å¼é–‹å§‹] ---
try:
    print(f"\n>> åƒ¹æ ¼çˆ¬èŸ² v3.4 ({website_name} æ°¸ä¹…ç‰ˆ - JPY-Only + API å„ªåŒ– + æ–°å‹•æ…‹ URL) å·²å•Ÿå‹•...")
    print(">> æ­¥é©Ÿ 1/5: æ­£åœ¨è®€å– `Card_Master` (å„ªåŒ–æ¨¡å¼)...") 
    master_worksheet = gc.open(sheet_name).worksheet(master_worksheet_name)
    history_worksheet = gc.open(sheet_name).worksheet(history_worksheet_name)
    
    # --- ã€v3.4 API å„ªåŒ–ã€‘ ---
    print(" Â  Â  -> æ­£åœ¨è®€å– Card_Number (B æ¬„)...")
    all_card_numbers = master_worksheet.col_values(2) 
    existing_card_numbers = set(all_card_numbers[1:]) 
    print(f"âœ… è®€å–æˆåŠŸï¼Œè³‡æ–™åº«ä¸­ç¾æœ‰ {len(existing_card_numbers)} æ¢å¡è™Ÿç´€éŒ„ä»¥ä¾›åƒè€ƒã€‚")
    # --- ã€å„ªåŒ–çµæŸã€‘ ---

    # --- ã€v3.4ã€‘ æ­¥é©Ÿ 2 (ç²å–åŒ¯ç‡) å·²ç§»é™¤ ---

    with sync_playwright() as p:
        print("\n>> æ­¥é©Ÿ 2/5: æ­£åœ¨å•Ÿå‹• Playwright ç€è¦½å™¨...") 
        browser = p.firefox.launch(headless=True)
        page = browser.new_page()
        print("âœ… Playwright ç€è¦½å™¨æº–å‚™å°±ç·’ã€‚")

        # --- ã€v3.4ã€‘ æ­¥é©Ÿ 3: å‹•æ…‹ç²å–ç³»åˆ— URL ---
        print(f"\n>> æ­¥é©Ÿ 3/5: é–‹å§‹å‹•æ…‹æƒæ OP ç³»åˆ—å°ˆæ«ƒ (å¾ Pack/Series é é¢)...") 
        DYNAMIC_SERIES_URLS = get_series_urls(page, SERIES_PAGE_URL) # ä¸å†éœ€è¦ selector åƒæ•¸
        
        if not DYNAMIC_SERIES_URLS:
            print("âŒ éŒ¯èª¤: æœªèƒ½å¾ç³»åˆ—é é¢ç²å–ä»»ä½• OP ç³»åˆ— URLï¼Œä»»å‹™ä¸­æ­¢ã€‚")
            browser.close(); exit()
        
        print(f"âœ… å‹•æ…‹æƒæå®Œç•¢ï¼Œå°‡æƒè•© {len(DYNAMIC_SERIES_URLS)} å€‹ç³»åˆ—å°ˆæ«ƒã€‚")
        all_mercadop_cards = {}
        # --- ã€v3.4 æ­¥é©Ÿ 3 çµæŸã€‘ ---

        # --- ã€v3.4ã€‘ æ­¥é©Ÿ 4: æƒè•©ç²å–çš„ç³»åˆ— URL ---
        print(f"\n>> æ­¥é©Ÿ 4/5: é–‹å§‹æƒè•© {len(DYNAMIC_SERIES_URLS)} å€‹æ ¸å¿ƒç³»åˆ—å°ˆæ«ƒ...") 

        for i, series_url_path in enumerate(DYNAMIC_SERIES_URLS):
            series_url = base_url + series_url_path 
            print(f"  -> æ­£åœ¨æƒè•©å°ˆæ«ƒ {i+1}/{len(DYNAMIC_SERIES_URLS)}: {series_url}")
            current_page = 1
            consecutive_failures = 0  # é€£çºŒå¤±æ•—è¨ˆæ•¸å™¨
            max_pages = 100  # æœ€å¤§é æ•¸é™åˆ¶ï¼Œé˜²æ­¢ç„¡é™å¾ªç’°
            
            while current_page <= max_pages:
                page_url = f"{series_url}?page={current_page}"
                if current_page == 1: page_url = series_url
                print(f"     -> æ­£åœ¨æƒè•©é é¢ {current_page}...")
                try:
                    page.goto(page_url, wait_until='networkidle', timeout=30000) 
                    page.wait_for_selector("li.list_item_cell", timeout=10000)
                    page_html = page.content()
                    soup = BeautifulSoup(page_html, 'html.parser')
                    card_items = soup.select("li.list_item_cell")
                    if not card_items: 
                        print("     -> æ­¤é é¢æ²’æœ‰å•†å“ï¼Œå·²åˆ°é”æœ«é ã€‚")
                        break
                    print(f"     -> åœ¨æ­¤é é¢ç™¼ç¾ {len(card_items)} å€‹å•†å“ã€‚")
                    
                    consecutive_failures = 0  # æˆåŠŸå¾Œé‡ç½®å¤±æ•—è¨ˆæ•¸

                    for item in card_items:
                        item_data = item.find('div', class_='item_data')
                        if not item_data: continue
                        name_tag = item_data.find('span', class_='goods_name'); price_tag = item_data.find('span', class_='figure'); stock_tag = item_data.find('p', class_='stock'); model_tag = item_data.find('span', class_='model_number_value')
                        if not name_tag or not price_tag: continue
                        item_name = name_tag.text.strip(); price_text = price_tag.text.strip(); price_jpy = int(re.sub(r'[^\d]', '', price_text))

                        status = "In Stock"
                        if (stock_tag and "soldout_mer" in stock_tag.get('class', [])) or \
                           (stock_tag and "SOLD OUT" in stock_tag.text) or \
                           (stock_tag and "å“åˆ‡ã‚Œ" in stock_tag.text) or \
                           'soldout' in item.get('class', []): status = "Out of Stock"
                        elif stock_tag and ("æ®‹ã‚Š" in stock_tag.text or "åœ¨åº«" in stock_tag.text): status = "In Stock"

                        item_card_number = ""
                        if model_tag:
                            match = re.search(r'([A-Z]{2,3}\d{2,3}-?[A-Z]?\d{3})', model_tag.text)
                            if match: item_card_number = match.group(1)
                        if not item_card_number:
                            match_name = re.search(r'([A-Z]{2,3}\d{2,3}-?[A-Z]?\d{3})', item_name)
                            if match_name: item_card_number = match_name.group(1)
                        if not item_card_number: continue

                        image_url = ""
                        image_container = item_data.select_one('div.global_photo')
                        if image_container and image_container.has_attr('data-src'):
                            image_url = image_container['data-src'].strip() 
                            if image_url.startswith('//'): image_url = 'https:' + image_url
                            elif image_url.startswith('/'): image_url = base_url + image_url

                        all_mercadop_cards[(item_card_number, item_name)] = {'price_jpy': price_jpy, 'status': status, 'image_url': image_url}

                    next_page_link = soup.select_one('a.to_next_page')
                    if not next_page_link: print("     -> æ­¤ç³»åˆ—å·²æƒè•©å®Œç•¢ï¼ˆæ²’æœ‰ä¸‹ä¸€é ï¼‰ã€‚"); break
                    current_page += 1; time.sleep(random.uniform(1, 3))
                    
                except PlaywrightTimeoutError:
                    consecutive_failures += 1
                    if current_page == 1: 
                        print("     -> è­¦å‘Šï¼šç¬¬ 1 é ç­‰å¾…è¶…æ™‚ï¼Œè·³éæ­¤å°ˆæ«ƒ...")
                        break
                    else: 
                        print(f"     -> åœ¨ç¬¬ {current_page} é ç­‰å¾…è¶…æ™‚...")
                        if consecutive_failures >= 3:
                            print(f"     -> é€£çºŒ {consecutive_failures} æ¬¡è¶…æ™‚ï¼Œè·³éæ­¤å°ˆæ«ƒ...")
                            break
                        current_page += 1  # å˜—è©¦ä¸‹ä¸€é 
                        continue
                        
                except Exception as e: 
                    consecutive_failures += 1
                    print(f"     -> æƒè•©é é¢ {current_page} æ™‚å¤±æ•—ã€‚éŒ¯èª¤: {e}")
                    if consecutive_failures >= 3:
                        print(f"     -> é€£çºŒ {consecutive_failures} æ¬¡å¤±æ•—ï¼Œè·³éæ­¤å°ˆæ«ƒ...")
                        break
                    current_page += 1  # å˜—è©¦ä¸‹ä¸€é 
                    continue

        print(f"\nâœ… æ‰€æœ‰å‹•æ…‹ç²å–çš„å°ˆæ«ƒæƒè•©å®Œç•¢ï¼Œå…±æ•ç² {len(all_mercadop_cards)} ç¨®å¡ç‰Œçš„æƒ…å ±ã€‚")

        print("\n>> æ­¥é©Ÿ 4/5: é–‹å§‹åŸ·è¡Œæƒ…å ±æ“´å¼µèˆ‡åƒ¹æ ¼è¨˜éŒ„...") 
        new_cards_to_add = []
        price_history_to_add = []
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        for (item_card_number, item_name), card_info in all_mercadop_cards.items():
            price_jpy = card_info['price_jpy']; status = card_info['status']; image_url = card_info['image_url']
            # --- ã€v3.4ã€‘ price_hkd å·²ç§»é™¤ ---

            # --- æƒ…å ±æ“´å¼µ ---
            if item_card_number not in existing_card_numbers:
                print(f" Â  Â  -> âœ¨ ç™¼ç¾æ–°å¡ç‰Œï¼ {item_card_number} {item_name}")
                rarity = "Unknown"; card_type = "Unknown"
                if "(ãƒ‘ãƒ©ãƒ¬ãƒ«)" in item_name or "ãƒ‘ãƒ©ãƒ¬ãƒ«" in item_name: rarity = "P"
                elif "SEC" in item_name: rarity = "SEC"
                elif "SR" in item_name: rarity = "SR"
                elif "R" in item_name: rarity = "R"
                elif "UC" in item_name: rarity = "UC"
                elif "C" in item_name: rarity = "C"
                elif "L" in item_name: rarity = "L"
                if "ãƒªãƒ¼ãƒ€ãƒ¼" in item_name: card_type = "LEADER"
                elif "ã‚­ãƒ£ãƒ©" in item_name or "ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼" in item_name: card_type = "CHARACTER"
                elif "ã‚¤ãƒ™ãƒ³ãƒˆ" in item_name: card_type = "EVENT"
                elif "ã‚¹ãƒ†ãƒ¼ã‚¸" in item_name: card_type = "STAGE"
                unique_id = f"{item_card_number}_{rarity}"; set_id = item_card_number.split('-')[0] if '-' in item_card_number else item_card_number[:4]

                new_cards_to_add.append([
                    unique_id, item_card_number, game_title, set_id,
                    item_name, rarity,
                    image_url, 
                    card_type  
                ])
                # existing_cards_map removed
                existing_card_numbers.add(item_card_number)
                print(f" Â  Â  Â  -> å·²æº–å‚™å°‡å…¶æ·»åŠ åˆ° `Card_Master`ã€‚")

            # --- åƒ¹æ ¼æ­·å²è¨˜éŒ„ ---
            history_unique_id = f"{item_card_number}_{item_name}"
            history_id = f"{history_unique_id}_{website_name}_{timestamp}"
            set_id_history = item_card_number.split('-')[0] if '-' in item_card_number else item_card_number[:4]

            # --- ã€v3.4 JPY-Only çµæ§‹ (9 æ¬„)ã€‘ ---
            price_history_to_add.append([
                history_id, history_unique_id, website_name,
                price_jpy,  # D: Sell_Price_JPY
                "N/A",      # E: Buy_Price_JPY
                timestamp,  # F: Timestamp
                status,     # G: Status
                set_id_history, # H: Set_ID
                image_url   # I: Image_URL
            ])

        print(f"\nâœ… æƒ…å ±è™•ç†å®Œç•¢ã€‚æº–å‚™æ–°å¢ {len(new_cards_to_add)} å¼µæ–°å¡ç‰Œï¼Œè¨˜éŒ„ {len(price_history_to_add)} æ¢åƒ¹æ ¼æƒ…å ± (JPY)ã€‚")

        if price_history_to_add:
             print(">> æ­£åœ¨å°æ•ç²çš„æƒ…å ±é€²è¡Œå¾Œç«¯æ’åº..."); price_history_to_add.sort(key=lambda record: (record[1], record[5])); print("âœ… æƒ…å ±æ’åºå®Œç•¢ã€‚")

        print("\n>> æ­¥é©Ÿ 5/5: æ­£åœ¨å°‡æ•¸æ“šå¯«å…¥ Google Sheet...") 
        if new_cards_to_add:
            print(f" Â  Â  -> æ­£åœ¨å°‡ {len(new_cards_to_add)} å¼µæ–°å¡ç‰Œå¯«å…¥ `Card_Master`...")
            master_worksheet.append_rows(new_cards_to_add, value_input_option='USER_ENTERED')
            print(" Â  Â  -> âœ… æ–°å¡ç‰Œå¯«å…¥æˆåŠŸï¼")
        else: print(" Â  Â  -> æœªç™¼ç¾éœ€è¦æ·»åŠ åˆ° `Card_Master` çš„æ–°å¡ç‰Œã€‚")

        if price_history_to_add:
            print(f" Â  Â  -> æ­£åœ¨å°‡ {len(price_history_to_add)} æ¢åƒ¹æ ¼æƒ…å ± (JPY-Only) **è¿½åŠ **åˆ° `Price_History`...")
            history_worksheet.append_rows(price_history_to_add, value_input_option='USER_ENTERED')
            print(" Â  Â  -> âœ… åƒ¹æ ¼æƒ…å ±è¿½åŠ æˆåŠŸï¼")
        else: print(" Â  Â  -> æœªæ•ç²åˆ°éœ€è¦æ·»åŠ åˆ° `Price_History` çš„åƒ¹æ ¼æƒ…å ±ã€‚")

        print("\n\nğŸ‰ğŸ‰ğŸ‰ æ­å–œï¼Mercadop (JPY-Only + å‹•æ…‹ URL) å¾æœä»»å‹™å®Œæˆï¼ ğŸ‰ğŸ‰ğŸ‰")

        browser.close()

except Exception as e:
    print(f"\nâŒâŒâŒ ç™¼ç”Ÿåš´é‡éŒ¯èª¤ âŒâŒâŒ"); print(f"éŒ¯èª¤è©³æƒ…: {e}")
    if 'browser' in locals() and browser.is_connected(): browser.close()