# =========================================================
# Phase 1, Block 2.1: åƒ¹æ ¼çˆ¬èŸ² (Price Scraper) - Union Arena å”®åƒ¹ v1.1 (JPY-Only + API å„ªåŒ–)
# Author: é›»ç‹
# æˆ°è¡“: ã€v1.0 URL æ¸…æ½”ã€‘+ã€v1.1 JPY-Only + API å„ªåŒ–ã€‘
# Update: v1.1 - å¾¹åº•ç§»é™¤æ‰€æœ‰åŒ¯ç‡ (HKD) ç›¸é—œä»£ç¢¼ã€‚
#         æ­¤è…³æœ¬ç¾åœ¨åªè² è²¬æŠ“å– JPY åŸå§‹åƒ¹æ ¼ä¸¦å¯«å…¥ Sheet (9æ¬„çµæ§‹)ã€‚
#         ã€æ ¸å¿ƒã€‘: å°‡ get_all_records() æ›¿æ›ç‚º col_values(2)ï¼Œ
#                   è§£æ±ºå›  Card_Master éå¤§å°è‡´çš„ APIError: [500] éŒ¯èª¤ã€‚
# =========================================================
import gspread
from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import InstalledAppFlow
from google.auth.transport.requests import Request
import os.path, time, re, random
from datetime import datetime
from bs4 import BeautifulSoup
import pandas as pd
from playwright.sync_api import sync_playwright, TimeoutError as PlaywrightTimeoutError
# import requests # <-- ã€v1.1ã€‘ å·²ç§»é™¤

# --- [æ­¥é©Ÿ A: æœ¬åœ°ç«¯ Google Sheets æˆæ¬Š] --- 
print(">> æ­¥é©Ÿ A: æ­£åœ¨é€²è¡Œæœ¬åœ°ç«¯ Google Sheets æˆæ¬Š...")
SCOPES = ['https://www.googleapis.com/auth/spreadsheets', 'https://www.googleapis.com/auth/drive']
creds = None
# ... (æˆæ¬Šä»£ç¢¼ä¸è®Š) ...
if os.path.exists('token.json'): creds = Credentials.from_authorized_user_file('token.json', SCOPES)
if not creds or not creds.valid:
    if creds and creds.expired and creds.refresh_token:
        try: creds.refresh(Request())
        except Exception as e:
            print(f"âŒ åˆ·æ–° Token å¤±æ•—: {e}");
            if os.path.exists('credentials.json'):
                flow = InstalledAppFlow.from_client_secrets_file('credentials.json', SCOPES); creds = flow.run_local_server(port=0)
            else: print("\nâŒ éŒ¯èª¤: æ‰¾ä¸åˆ° 'credentials.json'ã€‚"); exit()
    else:
        if not os.path.exists('credentials.json'): print("\nâŒ éŒ¯èª¤: æ‰¾ä¸åˆ° 'credentials.json'ã€‚"); exit()
        flow = InstalledAppFlow.from_client_secrets_file('credentials.json', SCOPES); creds = flow.run_local_server(port=0)
    with open('token.json', 'w') as token: token.write(creds.to_json())
gc = gspread.authorize(creds)
print("âœ… Google Sheets æˆæ¬ŠæˆåŠŸã€‚")

# --- [UA è¨­å®šå€åŸŸ] --- 
sheet_name = "å¡ç‰Œåƒ¹æ ¼è¿½è¹¤ç³»çµ± - Command Deck"
master_worksheet_name = "Card_Master"
history_worksheet_name = "Price_History"
website_name = "Merucard-Uniari"
base_url = "https://www.merucarduniari.jp"
game_title = "UnionArena" # ä¿®æ­£ç‚º UnionArena
SERIES_INDEX_URL = "https://www.merucarduniari.jp/page/pack"

# --- ã€v1.1ã€‘ åŒ¯ç‡æ›ç®—å‡½æ•¸å·²ç§»é™¤ --- 

# --- [v1.0.3 å‡½æ•¸] --- 
def get_all_series_links(page):
    print(f" Â  Â  -> æ­£åœ¨è¨ªå•ç³»åˆ—ç¸½è¦½: {SERIES_INDEX_URL}...")
    try:
        page.goto(SERIES_INDEX_URL, wait_until='domcontentloaded', timeout=60000)
        print(" Â  Â  -> HTMLæ–‡æª”å·²åŠ è¼‰ã€‚æ­£åœ¨ã€è€å¿ƒè§€å¯Ÿã€‘ç³»åˆ—é¸å–®å‡ºç¾...")
        page.wait_for_selector("aside#left_side_col section.pickupcategory_nav_box", timeout=45000) 
        print(" Â  Â  -> âœ… åµæ¸¬åˆ°ç³»åˆ—é¸å–®ã€‚")
        html = page.content()
        soup = BeautifulSoup(html, 'html.parser')
        links = []
        series_links = soup.select("aside#left_side_col section.pickupcategory_nav_box li.itemlist_nav_item a")
        for link in series_links:
            href = link.get('href')
            name = link.select_one("span.nav_label").get_text(strip=True) if link.select_one("span.nav_label") else ""
            if href and ('/product-group/' in href) and ('BTã€‘' in name or 'STã€‘' in name):
                if href.startswith(base_url): href = href.replace(base_url, "") 
                href_without_params = href.split('?')[0] # ç§»é™¤åƒæ•¸
                if href_without_params not in links:
                    links.append(href_without_params)
        print(f" Â  Â  -> âœ… å‹•æ…‹æƒæå®Œç•¢ï¼Œç™¼ç¾ {len(links)} å€‹ UA ç³»åˆ—å°ˆæ«ƒã€‚")
        return links
    except Exception as e:
        print(f" Â  Â  -> âŒ å‹•æ…‹æƒæç³»åˆ—é é¢å¤±æ•—: {e}")
        return []

# --- [ä¸»ç¨‹å¼é–‹å§‹] ---
try:
    print(f"\n>> åƒ¹æ ¼çˆ¬èŸ² v1.1 ({website_name} å”®åƒ¹ - JPY-Only + API å„ªåŒ–) å·²å•Ÿå‹•...")
    print(">> æ­¥é©Ÿ 1/5: æ­£åœ¨è®€å– `Card_Master` (å„ªåŒ–æ¨¡å¼)...") # æ­¥é©Ÿé‡ç·¨
    master_worksheet = gc.open(sheet_name).worksheet(master_worksheet_name)
    history_worksheet = gc.open(sheet_name).worksheet(history_worksheet_name)
    
    # --- ã€v1.1 API å„ªåŒ–ã€‘ ---
    print(" Â  Â  -> æ­£åœ¨è®€å– Card_Number (B æ¬„)...")
    all_card_numbers = master_worksheet.col_values(2) 
    existing_card_numbers = set(all_card_numbers[1:]) 
    print(f"âœ… è®€å–æˆåŠŸï¼Œè³‡æ–™åº«ä¸­ç¾æœ‰ {len(existing_card_numbers)} æ¢å¡è™Ÿç´€éŒ„ä»¥ä¾›åƒè€ƒã€‚")
    # --- ã€å„ªåŒ–çµæŸã€‘ ---

    # --- ã€v1.1ã€‘ æ­¥é©Ÿ 2 (ç²å–åŒ¯ç‡) å·²ç§»é™¤ ---

    with sync_playwright() as p:
        print("\n>> æ­¥é©Ÿ 2/5: æ­£åœ¨å•Ÿå‹• Playwright ç€è¦½å™¨...") # æ­¥é©Ÿé‡ç·¨
        browser = p.firefox.launch(headless=True)
        page = browser.new_page()
        print("âœ… Playwright ç€è¦½å™¨æº–å‚™å°±ç·’ã€‚")

        print("\n>> æ­¥é©Ÿ 3/5: é–‹å§‹å‹•æ…‹æƒæ UA ç³»åˆ—å°ˆæ«ƒ...") # æ­¥é©Ÿé‡ç·¨
        UA_SERIES_URLS = get_all_series_links(page) 
        
        if not UA_SERIES_URLS:
            print("âŒ éŒ¯èª¤: æœªèƒ½ç²å–ä»»ä½• UA ç³»åˆ— URLï¼Œä»»å‹™ä¸­æ­¢ã€‚")
            browser.close(); exit()
            
        all_uniari_cards = {}

        for i, series_url_path in enumerate(UA_SERIES_URLS):
            series_url = base_url + series_url_path
            print(f" Â -> æ­£åœ¨æƒè•©å°ˆæ«ƒ {i+1}/{len(UA_SERIES_URLS)}: {series_url}")
            current_page = 1
            while True:
                page_url = f"{series_url}?page={current_page}"
                if current_page == 1: page_url = series_url
                print(f" Â  Â  -> æ­£åœ¨æƒè•©é é¢ {current_page}...")
                try:
                    page.goto(page_url, wait_until='networkidle', timeout=30000) 
                    page.wait_for_selector("li.list_item_cell", timeout=10000)
                    page_html = page.content()
                    soup = BeautifulSoup(page_html, 'html.parser')
                    card_items = soup.select("li.list_item_cell")
                    if not card_items: break
                    print(f" Â  Â  -> åœ¨æ­¤é é¢ç™¼ç¾ {len(card_items)} å€‹å•†å“ã€‚")

                    for item in card_items:
                        item_data = item.find('div', class_='item_data');
                        if not item_data: continue
                        name_tag = item_data.find('span', class_='goods_name'); price_tag = item_data.find('span', class_='figure'); stock_tag = item_data.find('p', class_='stock'); model_tag = item_data.find('span', class_='model_number_value')
                        if not name_tag or not price_tag: continue
                        item_name = name_tag.text.strip(); price_text = price_tag.text.strip(); price_jpy = int(re.sub(r'[^\d]', '', price_text))

                        status = "In Stock"
                        if (stock_tag and "soldout_mer" in stock_tag.get('class', [])) or \
                           (stock_tag and "SOLD OUT" in stock_tag.text) or (stock_tag and "å“åˆ‡ã‚Œ" in stock_tag.text) or \
                           'soldout' in item.get('class', []): status = "Out of Stock"
                        elif stock_tag and ("æ®‹ã‚Š" in stock_tag.text or "åœ¨åº«" in stock_tag.text): status = "In Stock"

                        item_card_number = ""
                        ua_regex = r'([A-Z]{2,}\d{2,}[A-Z]{0,2}/[A-Z0-9-]+-[A-Z0-9]+)'
                        if model_tag:
                            match = re.search(ua_regex, model_tag.text)
                            if match: item_card_number = match.group(1).strip()
                        if not item_card_number:
                            match_name = re.search(ua_regex, item_name)
                            if match_name: item_card_number = match_name.group(1).strip()
                        if not item_card_number:
                            ua_regex_alt = r'([A-Z]{0,}[A-Z]{2,}\d{2,}[A-Z]{0,2}/[A-Z0-9-]+-[A-Z0-9]+)'
                            match_alt = re.search(ua_regex_alt, item_name)
                            if match_alt: item_card_number = match_alt.group(1).strip()
                        if not item_card_number: continue

                        # (v1.0.4 URL æ¸…æ½” .strip() + .replace() ä¿®æ­£)
                        image_url = ""
                        image_container = item_data.select_one('div.global_photo')
                        if image_container and image_container.has_attr('data-src'):
                            image_url = image_container['data-src'].strip() 
                            image_url = image_url.replace(" ", "%20")   
                            if image_url.startswith('//'): image_url = 'https:' + image_url
                            elif image_url.startswith('/'): image_url = base_url + image_url

                        all_uniari_cards[(item_card_number, item_name)] = {'price_jpy': price_jpy, 'status': status, 'image_url': image_url}

                    next_page_link = soup.select_one('a.to_next_page')
                    if not next_page_link: print(" Â  Â  -> æ­¤ç³»åˆ—å·²æƒè•©å®Œç•¢ï¼ˆæ²’æœ‰ä¸‹ä¸€é ï¼‰ã€‚"); break
                    current_page += 1; time.sleep(random.uniform(1, 3))
                except PlaywrightTimeoutError:
                    if current_page == 1: print(" Â  Â  -> è­¦å‘Šï¼šæ­¤ç³»åˆ—å¯èƒ½ç‚ºç©ºæˆ–åŠ è¼‰è¶…æ™‚...")
                    else: print(f" Â  Â  -> åœ¨ç¬¬ {current_page} é ç­‰å¾…è¶…æ™‚ï¼Œè·³è½‰åˆ°ä¸‹å€‹ç³»åˆ—ã€‚")
                    break
                except Exception as e: print(f" Â  Â  -> æƒè•©é é¢ {current_page} æ™‚å¤±æ•—ã€‚éŒ¯èª¤: {e}"); break

        print(f"\nâœ… æ‰€æœ‰ UA å°ˆæ«ƒæƒè•©å®Œç•¢ï¼Œå…±æ•ç² {len(all_uniari_cards)} ç¨®å¡ç‰Œçš„æƒ…å ±ã€‚")

        print("\n>> æ­¥é©Ÿ 4/5: é–‹å§‹åŸ·è¡Œæƒ…å ±æ“´å¼µ (UA) èˆ‡åƒ¹æ ¼è¨˜éŒ„...") # æ­¥é©Ÿé‡ç·¨
        new_cards_to_add = []
        price_history_to_add = []
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        for (item_card_number, item_name), card_info in all_uniari_cards.items():
            price_jpy = card_info['price_jpy']; status = card_info['status']; image_url = card_info['image_url']
            # --- ã€v1.1ã€‘ price_hkd å·²ç§»é™¤ ---

            # --- [æƒ…å ±æ“´å¼µ: Card_Master] ---
            if item_card_number not in existing_card_numbers:
                print(f" Â  Â  -> âœ¨ ç™¼ç¾æ–° UA å¡ç‰Œï¼ {item_card_number} {item_name}")
                rarity = "Unknown"; card_type = "Unknown"
                if "SRâ˜…â˜…" in item_name or "â˜…â˜…" in item_name: rarity = "SRâ˜…â˜…"
                elif "SRâ˜…" in item_name or "â˜…" in item_name: rarity = "SRâ˜…" 
                elif "Râ˜…" in item_name: rarity = "Râ˜…"
                elif "Uâ˜…" in item_name: rarity = "Uâ˜…"
                elif "Câ˜…" in item_name: rarity = "Câ˜…"
                elif "AP" in item_name: rarity = "AP"
                elif "SR" in item_name: rarity = "SR"
                elif "R" in item_name: rarity = "R"
                elif "U" in item_name: rarity = "U"
                elif "C" in item_name: rarity = "C"
                elif "L" in item_name: rarity = "L" 
                if "ã€ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã€‘" in item_name: card_type = "CHARACTER"
                elif "ã€ã‚¤ãƒ™ãƒ³ãƒˆã€‘" in item_name: card_type = "EVENT"
                elif "ã€ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã€‘" in item_name: card_type = "FIELD"
                elif "ã€ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒã‚¤ãƒ³ãƒˆã€‘" in item_name: card_type = "ACTION POINT"
                set_id = item_card_number.split('/')[0] if '/' in item_card_number else "UA_Unknown"
                unique_id = f"{item_card_number}_{rarity}"
                new_cards_to_add.append([
                    unique_id, item_card_number, game_title, set_id,
                    item_name, rarity, image_url, card_type
                ])
                # existing_cards_map removed
                existing_card_numbers.add(item_card_number)
                print(f" Â  Â  Â  -> å·²æº–å‚™å°‡å…¶æ·»åŠ åˆ° `Card_Master`ã€‚")

            # --- [åƒ¹æ ¼è¨˜éŒ„: Price_History] ---
            history_unique_id = f"{item_card_number}_{item_name}"
            history_id = f"{history_unique_id}_{website_name}_{timestamp}"
            set_id_history = item_card_number.split('/')[0] if '/' in item_card_number else "UA_Unknown"

            # --- ã€v1.1 JPY-Only çµæ§‹ (9 æ¬„)ã€‘ ---
            price_history_to_add.append([
                history_id, history_unique_id, website_name,
                price_jpy,  # D: Sell_Price_JPY
                "N/A",      # E: Buy_Price_JPY
                timestamp,  # F: Timestamp
                status,     # G: Status
                set_id_history, # H: Set_ID
                image_url   # I: Image_URL
            ])

        print(f"\nâœ… æƒ…å ±è™•ç†å®Œç•¢ã€‚æº–å‚™æ–°å¢ {len(new_cards_to_add)} å¼µæ–° UA å¡ç‰Œï¼Œè¨˜éŒ„ {len(price_history_to_add)} æ¢ UA åƒ¹æ ¼æƒ…å ± (JPY)ã€‚")

        if price_history_to_add:
             print(">> æ­£åœ¨å°æ•ç²çš„æƒ…å ±é€²è¡Œå¾Œç«¯æ’åº..."); price_history_to_add.sort(key=lambda record: (record[1], record[5])); print("âœ… æƒ…å ±æ’åºå®Œç•¢ã€‚")

        print("\n>> æ­¥é©Ÿ 5/5: æ­£åœ¨å°‡æ•¸æ“šå¯«å…¥ Google Sheet...") # æ­¥é©Ÿé‡ç·¨
        if new_cards_to_add:
            print(f" Â  Â  -> æ­£åœ¨å°‡ {len(new_cards_to_add)} å¼µæ–° UA å¡ç‰Œå¯«å…¥ `Card_Master`...")
            master_worksheet.append_rows(new_cards_to_add, value_input_option='USER_ENTERED')
            print(" Â  Â  -> âœ… æ–° UA å¡ç‰Œå¯«å…¥æˆåŠŸï¼")
        else: print(" Â  Â  -> æœªç™¼ç¾éœ€è¦æ·»åŠ åˆ° `Card_Master` çš„æ–° UA å¡ç‰Œã€‚")

        if price_history_to_add:
            print(f" Â  Â  -> æ­£åœ¨å°‡ {len(price_history_to_add)} æ¢ UA åƒ¹æ ¼æƒ…å ± (JPY-Only) **è¿½åŠ **åˆ° `Price_History`...")
            history_worksheet.append_rows(price_history_to_add, value_input_option='USER_ENTERED')
            print(" Â  Â  -> âœ… UA åƒ¹æ ¼æƒ…å ±è¿½åŠ æˆåŠŸï¼")
        else:
            print(" Â  Â  -> æœªæ•ç²åˆ°éœ€è¦æ·»åŠ åˆ° `Price_History` çš„ UA åƒ¹æ ¼æƒ…å ±ã€‚")

        print("\n\nğŸ‰ğŸ‰ğŸ‰ æ­å–œï¼Union Arena å”®åƒ¹ (JPY-Only) å¾æœä»»å‹™å®Œæˆï¼ ğŸ‰ğŸ‰ğŸ‰")
        browser.close()

except Exception as e:
    print(f"\nâŒâŒâŒ ç™¼ç”Ÿåš´é‡éŒ¯èª¤ âŒâŒâŒ"); print(f"éŒ¯èª¤è©³æƒ…: {e}")
    if 'browser' in locals() and browser.is_connected(): browser.close()